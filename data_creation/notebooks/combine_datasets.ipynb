{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8nCW-5Fm73A",
        "outputId": "a0747099-cf7d-4bbd-e57a-b3c7153a6f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined data saved to 'combined_bus_status.csv'\n",
            "Combined dataset contains 163 rows\n",
            "\n",
            "Columns in combined dataset:\n",
            "['bus_id', 'trip_id', 'route_id', 'current_lat', 'current_lon', 'next_stop_id', 'next_stop_lat', 'next_stop_lon', 'next_stop_name', 'current_time', 'position_timestamp', 'expected_arrival_time', 'time_to_arrival_seconds', 'distance_to_stop_meters', 'speed_m_s', 'status', 'stop_sequence', 'wheelchair_boarding']\n",
            "\n",
            "First few rows:\n",
            "   bus_id                           trip_id  route_id  current_lat  \\\n",
            "0    1010  5341__201065_Timetable_-_2025-02       211    43.854668   \n",
            "1    6100  1475__201086_Timetable_-_2025-02       900    43.884548   \n",
            "2    6101  3506__201038_Timetable_-_2025-02       302    43.946533   \n",
            "3    6102  3003__201072_Timetable_-_2025-02       101    43.820915   \n",
            "4    6103  1555__401094_Timetable_-_2025-02       900    43.857716   \n",
            "\n",
            "   current_lon  next_stop_id  next_stop_lat  next_stop_lon  \\\n",
            "0   -79.055603          1601      43.853329     -79.060678   \n",
            "1   -78.921936           393      43.882884     -78.929034   \n",
            "2   -78.893951          2712      43.947746     -78.895601   \n",
            "3   -79.054550          1712      43.824595     -79.053029   \n",
            "4   -79.040764          2238      43.858841     -79.035728   \n",
            "\n",
            "                    next_stop_name         current_time   position_timestamp  \\\n",
            "0   Kingston Westbound @ Elizabeth  2025-03-18T21:07:39  2025-03-18T21:07:14   \n",
            "1       Dundas Westbound @ Craydon  2025-03-18T21:07:39  2025-03-18T21:07:29   \n",
            "2       Simcoe Northbound @ Conlin  2025-03-18T21:07:39  2025-03-18T21:07:31   \n",
            "3  Northbound @ 1111 Squires Beach  2025-03-18T21:07:39  2025-03-18T21:07:15   \n",
            "4     Kingston Eastbound @ Ritchie  2025-03-18T21:07:39  2025-03-18T21:07:34   \n",
            "\n",
            "  expected_arrival_time  time_to_arrival_seconds  distance_to_stop_meters  \\\n",
            "0   2025-03-18T21:08:17                     38.0               433.299424   \n",
            "1   2025-03-18T21:09:27                    108.0               598.197597   \n",
            "2   2025-03-18T21:08:22                     43.0               188.750949   \n",
            "3   2025-03-18T21:08:14                     35.0               426.983834   \n",
            "4   2025-03-18T21:08:35                     56.0               422.710910   \n",
            "\n",
            "   speed_m_s   status  stop_sequence  wheelchair_boarding  \n",
            "0  11.402616  on-time             18                    1  \n",
            "1   5.538867     late             16                    2  \n",
            "2   4.389557  on-time              3                    1  \n",
            "3  12.199538  on-time             14                    2  \n",
            "4   7.548409  on-time             13                    1  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def combine_csv_files(file1, file2, output_file=None):\n",
        "    \"\"\"\n",
        "    Combines two CSV files with identical columns into a single DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - file1 (str): Path to the first CSV file\n",
        "    - file2 (str): Path to the second CSV file\n",
        "    - output_file (str, optional): Path to save the combined CSV. If None, no file is saved.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Combined DataFrame containing all rows from both files\n",
        "\n",
        "    Raises:\n",
        "    - ValueError: If the columns in the two files don't match\n",
        "    - FileNotFoundError: If either file cannot be found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the two CSV files\n",
        "        df1 = pd.read_csv(file1)\n",
        "        df2 = pd.read_csv(file2)\n",
        "\n",
        "        # Check if columns match\n",
        "        if set(df1.columns) != set(df2.columns):\n",
        "            raise ValueError(\"The CSV files have different columns. They must have identical columns to be combined.\")\n",
        "\n",
        "        # Combine the DataFrames\n",
        "        combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "        # Optionally save to a new CSV file\n",
        "        if output_file:\n",
        "            combined_df.to_csv(output_file, index=False)\n",
        "            print(f\"Combined data saved to '{output_file}'\")\n",
        "\n",
        "        print(f\"Combined dataset contains {len(combined_df)} rows\")\n",
        "        return combined_df\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: One or both files not found - {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        raise\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example filenames (replace with your actual file paths)\n",
        "    file1 = \"bus_status_dataset1.csv\"\n",
        "    file2 = \"bus_status_dataset.csv\"\n",
        "    output = \"combined_bus_status.csv\"\n",
        "\n",
        "    # Combine the files and save the result\n",
        "    combined_data = combine_csv_files(file1, file2, output)\n",
        "\n",
        "    # Display basic info about the combined data\n",
        "    print(\"\\nColumns in combined dataset:\")\n",
        "    print(combined_data.columns.tolist())\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(combined_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "\n",
        "def convert_to_unix_timestamp(csv_file, output_file):\n",
        "    \"\"\"\n",
        "    Converts Eastern Time timestamps in format '2025-03-22T15:54:50' to Unix timestamps.\n",
        "\n",
        "    Parameters:\n",
        "    - csv_file (str): Path to the input CSV file\n",
        "    - output_file (str): Path to save the modified CSV file\n",
        "    \"\"\"\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Define Eastern Time timezone\n",
        "    eastern = pytz.timezone('America/New_York')\n",
        "\n",
        "    # Function to convert a single timestamp to Unix time\n",
        "    def to_unix(timestamp):\n",
        "        try:\n",
        "            # Parse the timestamp string and localize to Eastern Time\n",
        "            dt = datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S')\n",
        "            dt = eastern.localize(dt)\n",
        "            # Convert to UTC and then to Unix timestamp\n",
        "            dt_utc = dt.astimezone(pytz.UTC)\n",
        "            return int(dt_utc.timestamp())\n",
        "        except (ValueError, TypeError, AttributeError):\n",
        "            return timestamp  # Return original value if conversion fails\n",
        "\n",
        "    # Identify columns that might contain timestamps\n",
        "    time_columns = []\n",
        "    for col in df.columns:\n",
        "        # Check if any value in the column matches the expected format\n",
        "        sample = df[col].dropna().iloc[0] if not df[col].dropna().empty else None\n",
        "        if sample and isinstance(sample, str) and len(sample) == 19 and 'T' in sample:\n",
        "            try:\n",
        "                datetime.strptime(sample, '%Y-%m-%dT%H:%M:%S')\n",
        "                time_columns.append(col)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    # Convert identified timestamp columns to Unix time\n",
        "    for col in time_columns:\n",
        "        df[col] = df[col].apply(to_unix)\n",
        "\n",
        "    # Save the modified DataFrame to a new CSV\n",
        "    df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Converted timestamps in columns: {time_columns}\")\n",
        "    print(f\"Modified dataset saved to '{output_file}'\")\n",
        "    print(f\"Number of rows: {len(df)}\")\n",
        "    print(\"\\nFirst few rows of the modified dataset:\")\n",
        "    print(df.head())\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = 'bus_status_dataset.csv'  # Replace with your CSV filename\n",
        "    output_file = 'bus_status_dataset_unix.csv'\n",
        "\n",
        "    convert_to_unix_timestamp(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXpXev8VrZWL",
        "outputId": "04bbc08b-d95a-479b-e8cf-92cd81e21cff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted timestamps in columns: ['current_time', 'position_timestamp', 'expected_arrival_time']\n",
            "Modified dataset saved to 'bus_status_dataset_unix.csv'\n",
            "Number of rows: 2146\n",
            "\n",
            "First few rows of the modified dataset:\n",
            "   bus_id                           trip_id  route_id  current_lat  \\\n",
            "0    1013  1607__261023_Timetable_-_2025-02       302    43.880016   \n",
            "1    6101  2940__261012_Timetable_-_2025-02       915    43.854618   \n",
            "2    6103   500__461021_Timetable_-_2025-02       403    43.886902   \n",
            "3    6104  1606__261025_Timetable_-_2025-02       905    43.903885   \n",
            "4    6106   563__461016_Timetable_-_2025-02       902    43.904518   \n",
            "\n",
            "   current_lon  next_stop_id  next_stop_lat  next_stop_lon  \\\n",
            "0   -78.942314           208      43.884855     -78.944315   \n",
            "1   -79.041199          2282      43.853799     -79.041066   \n",
            "2   -78.877434          1287      43.886764     -78.876312   \n",
            "3   -78.920181           281      43.899509     -78.918233   \n",
            "4   -78.833870          1136      43.905928     -78.827635   \n",
            "\n",
            "                        next_stop_name  current_time  position_timestamp  \\\n",
            "0   Brock Street Southbound @ Chestnut    1742664366          1742664347   \n",
            "1         Westney Northbound @ Ritchie    1742664366          1742664359   \n",
            "2                 Eastbound @ 431 Gibb    1742664366          1742664354   \n",
            "3  Thickson Northbound @ Canadian Oaks    1742664366          1742664347   \n",
            "4            King Westbound @ Keewatin    1742664366          1742664363   \n",
            "\n",
            "   expected_arrival_time  time_to_arrival_seconds  distance_to_stop_meters  \\\n",
            "0             1742664327                    -39.0               561.424596   \n",
            "1             1742664359                     -7.0                91.696428   \n",
            "2             1742664362                     -4.0                91.195978   \n",
            "3             1742664349                    -17.0               511.001159   \n",
            "4             1742664309                    -57.0               523.532739   \n",
            "\n",
            "    speed_m_s   status  stop_sequence  wheelchair_boarding  \n",
            "0  561.424596  on-time             41                    2  \n",
            "1   91.696428  on-time              2                    1  \n",
            "2   91.195978  on-time              2                    1  \n",
            "3  511.001159  on-time             17                    1  \n",
            "4  523.532739  on-time             18                    1  \n"
          ]
        }
      ]
    }
  ]
}